# This is a script containing functions dedicated to solving repeated data
# manipulation problems that anger Austin McCullough in dealing with the 
# inherently circular existence of a graduate student dealing with MRI/PET 
# imaging data. Anything that made him say "argh" more than five times was 
# placed here.

library(dplyr)
library(tidyr)
library(tidyselect)
library(tibble)
library(ggplot2)
library(lme4)
library(optimx)



#' csv import tool with special preset params
#' 
#' This returns a dataframe object with the
#' contents of the .csv file at the specified file path with the first row
#' automatically treated as column headers and string variables NOT treated as 
#' factors. In addition, the column with the specified id column name is 
#' manually converted to character to deal with the frequent issue of subject 
#' identifiers being treated as numbers.
#' 
#' @author Austin McCullough, \email{amccullough@wustl.edu}
#' @param file_path The file path to the .csv file to be imported
#' @param id_col_name Name of the subject identifier column in the .csv file
#' @return A dataframe object with the contents of the specified .csv file with 
#' the initial row treated as column headers, string vars NOT treated as factors
#' automatically, and the subject id column manually set as chars.
#' @seealso [base::read.csv()] this function wraps.
#' @examples 
#' data = csv_import("./file.csv","SUBJID")
#' @export
csv_import <- function(file_path, id_col_name, ...) {
  
  df = read.csv(file = file_path, header = TRUE, stringsAsFactors = FALSE)
  df[[id_col_name]] = as.character(df[[id_col_name]])
  
  df
}


#' Converts char string dates to date objects in R and stores them as unix time
#' 
#' Takes a column of dates in the specified string format, 
#' converts them to R Date objects, and unclasses them into integers 
#' representing number of days from January 1, 1970 (unix days).
#' 
#' @author Austin McCullough, \email{amccullough@wustl.edu}
#' @param .data dataframe object passed to the function via pipe
#' @param col_name column name that contains the date strings
#' @param date_format string denoting the format of the date strings
#' @return The original dataframe(s) via pipe now with replaced date column with 
#' integers representing number of days from January 1, 1970 (unix days).
#' @seealso [base::as.Date()] this function wraps.
#' @examples 
#' df = df %>% sterilize_dates("date","%m/%d/%Y")
#' @export
sterilize_dates <- function(.data, col_name, date_format, ...) {
  
  .data[[col_name]] = unclass(as.Date(.data[[col_name]], date_format))
  
  .data
}



## TO-DO: rename_column function that standardizes column names for later joins



#' Creates a column that contains the baseline value for each subject
#' on each entry row for that subject.
#' 
#' Creates a new column in the grouped dataframe passed to it via pipe 
#' that represents the value of the minimum entry for each subject on 
#' each entry row for that subject. This enables row-wise operations from other 
#' functions to include normalizations.
#' 
#' @author Austin McCullough, \email{amccullough@wustl.edu}
#' @param .data dataframe object passed to the function via pipe
#' @param date_col column name that contains the dates to determine min 
#' from.
#' @param out_col column name that will contain the min values for each subject
#' @return The original dataframe(s) via pipe now with new column that contains 
#' the minimum subject value on each row for that subject.
#' @seealso [dplyr::group_by()] dependency
#' @examples 
#' df = df %>% group_by(subject_id_col) %>%
#' define_baseline("Date","bl_Date")
#' @export
define_baseline <- function(.data, date_col, out_col, ...) {
  
  if(dplyr::is.grouped_df(.data)) {
    return(dplyr::do(.data, define_baseline(., date_col, out_col, ...)))
  }
  
  .data[[out_col]] = min(.data[[date_col]])
  
  .data
}



#' Normalizes values in a column to baseline values generated by the 
#' define_baseline function.
#' 
#' Creates a new column in the grouped dataframe passed to it via pipe that 
#' represents the value of the input_col column minus the value of the bl_col 
#' column. Values in this new column represent baseline normalized values of the
#' input column.
#' 
#' @author Austin McCullough, \email{amccullough@wustl.edu}
#' @param .data dataframe object passed to the function via pipe
#' @param input_col name of the column to be normalized
#' @param bl_col name of the column containing baseline values for each subject
#' @param out_col name to give the new baseline normalized column
#' @return The original dataframe via pipe now with new column that contains the
#' baseline normalized values based on the input_col and bl_col columns.
#' @seealso [dplyr::group_by()] dependency
#' @examples 
#' df = df %>% group_by(subject_id_col) %>%
#' define_baseline("Date","bl_Date") %>%
#' normalize_to_baseline("Date","bl_Date","bl_norm_Date")
normalize_to_baseline <- function(.data, input_col, bl_col, out_col, ...) {
  
  
  if(dplyr::is.grouped_df(.data)) {
    return(dplyr::do(.data, normalize_to_baseline(., input_col, bl_col, out_col, ...)))
  }
  
  .data[[out_col]] = .data[[input_col]] - .data[[bl_col]]
  
  .data
}



#' Runs a series of linear mixed effects models on each specified column of a 
#' dataframe using the specified model equation
#' 
#' Creates a list of linear mixed effects model outputs by running a series of 
#' lme models with each column of the dataframe df listed in the col_ind_list at
#' a time as the outcome variable. The fixed effects and random effects variables
#' for each model are defined by the fml_stub formula input. This input 
#' represents everything to the right of the "~" in the traditional way to 
#' write a lme model equation and should be defined before the call to this 
#' function as follows:
#' 
#' fml_stub = paste(c("fixed_effect", "random_effect"), collapse = "+")
#' 
#' This stub is combined with the outcome variable for each region and 
#' converted into a formula object using base::as.formula() and passed to 
#' lme4::lmer(). Currently, this function uses the 'L-BFGS-B' method for 
#' optimization of the lme models via the 'optimx' package. 
#' 
#' The resulting named list of models can be referenced and manipulated similarly 
#' to how a single lme model object would be by passing a list index along with 
#' the model list as follows:
#' 
#' summary(model_list[[1]]) or
#' summary(model_list[["list_entry_name"]])
#' 
#' This named list of models can then be passed to any function in the 
#' BILcore() package that asks for a model list to get specific formatted 
#' model output values.
#' 
#' @author Austin McCullough, \email{amccullough@wustl.edu}
#' @param df dataframe object containing all of the data needed to run models
#' @param fml_stub object containing everything in the model equation to the 
#' right side of the "~" (fixed effects + random effects)
#' @param col_ind_list list of column indexes to be used sequentially as the 
#' outcome variable
#' @return a list of named model objects corresponding to each column of data 
#' the model was specified to be run with.
#' @seealso [lme4::lmer()] dependency
#' @seealso [base::as.formula()] dependency
#' @examples 
#' 
run_regional_lme <- function(df, fml_stub, col_ind_list, ...) {
  
  regions_list = colnames(df) %>% 
  regions_list = colnames(df)[start_col_ind:end_col_ind]
  no_regions = length(regions_list)
  lme_fitlist = as.list(1:no_regions)
  names(lme_fitlist) = regions_list
  
  for (i in regions_list) {
    
    print(paste("Running entity:", i, " | ", which(regions_list==i), "/", no_regions))
    fml = as.formula(paste(i, "~", fml_stub))
    lme_fitlist[[i]] = lmer(fml, data = df, REML = FALSE, control = lmerControl(optimizer = 'optimx', optCtrl = list(method = 'L-BFGS-B')))
  }
  
  lme_fitlist
}



extract_regional_model_output <- function(model_list, value_type, ...) {
  
  value_index = switch(
    value_type,
    "beta" = 1,
    "stderr" = 2,
    "df" = 3,
    "tval" = 4,
    "pval" = 5
  )
  
  
  no_terms = length(fixef(model_list[[1]]))
  no_regions = length(model_list)
  
  output_df = data.frame(matrix(ncol = no_terms, nrow = no_regions))
  colnames(output_df) = names(fixef(model_list[[1]]))
  
  for (i in 1:no_regions) {
    rownames(output_df)[i] = as.character(names(model_list)[i])
    
    for (j in 1:no_terms) {
      output_df[i,j] = as.numeric(coef(summary(model_list[[i]]))[j,value_index])
    }
  }
  
  output_df
}



extract_regional_baseline_vals <- function(df, ...) {
  
  output_df = df %>% 
    group_by(blnorm_Date_year) %>% 
    summarize(across(where(is.numeric), ~ mean(.x, na.rm = TRUE))) %>% 
    filter(blnorm_Date_year == 0)
  
  output_df
} 



extract_regional_subject_intercepts <- function(model_list, ...) {
  
  no_terms = length(fixef(model_list[[1]]))
  no_regions = length(model_list)
  
  output_df = data.frame(matrix(ncol = no_terms, nrow = no_regions))
  colnames(output_df) = names(fixef(model_list[[1]]))
  
  for (i in 1:no_regions) {
    rownames(output_df)[i] = as.character(names(model_list)[i])
    
    for (j in 1:no_terms) {
      output_df[i,j] = as.numeric(coef(summary(model_list[[i]]))[j,5])
      
    }
  }
  
  output_df
}


## TODO
create_AO_PMMK <- function() {
  
}



extract_regional_subject_slopes <- function(model_list, ...) {
  
  
}



## TO-DO: finish this thought
split_results_by_rsf <- function(df, ...) {
  
  df = tibble::rownames_to_column(df, var = "REGION")
  
  rsf = dplyr::filter(df, grepl("rsf", REGION))
  norsf = dplyr::filter(df, !grepl("rsf", REGION))
  
  output_list = list(rsf, norsf)
  
  output_list
}



plot_regional_group_dynamics <- function(df, data_col, xlabel, ylabel, ylowlim, yhighlim, ...) {
  
  skinny_df = df %>%
    filter(blnorm_Date_year != 3) %>%
    group_by(MODELGROUP, CDRGBCAT, blnorm_Date_year) %>%
    summarize(mean = mean(.data[[data_col]]), sd = sd(.data[[data_col]]), n = n())
  
  skinny_df$se = skinny_df$sd/sqrt(skinny_df$n)
  
  plot = ggplot(skinny_df, aes(x=blnorm_Date_year, y=mean, group=MODELGROUP, color=MODELGROUP)) +
    theme_bw() +
    theme(legend.title = element_blank(), legend.position = c(0.85,0.1)) +
    geom_line() +
    geom_errorbar(aes(ymin = mean-se, ymax = mean+se), width = 0.2, position = position_dodge(width = 0.05)) +
    ylim(ylowlim,yhighlim) +
    scale_color_manual(values = c("blue","black","purple")) +
    labs(title = data_col) +
    xlab(xlabel) + ylab(ylabel) +
    facet_wrap(~CDRGBCAT)
  
  filename = paste("paper/mean_dynamics/PIB/",data_col,"_PIB",".tiff",sep="")
  
  ggsave(filename = filename, dpi = 600, width = 8.2, height = 8.2)
  
  plot
}
























































